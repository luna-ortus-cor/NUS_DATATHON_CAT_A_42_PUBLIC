{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /home/hentai/.local/lib/python3.10/site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: filelock in /home/hentai/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/hentai/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/hentai/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/hentai/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /home/hentai/.local/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hentai/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/hentai/.local/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /home/hentai/.local/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy==1.26.0 in /home/hentai/.local/lib/python3.10/site-packages (1.26.0)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.8.0)\n",
      "Requirement already satisfied: pyarrow in /home/hentai/.local/lib/python3.10/site-packages (19.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/hentai/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hentai/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hentai/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hentai/.local/lib/python3.10/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas numpy==1.26.0 scipy pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_info = pd.read_parquet('nus_agent_info_df.parquet')\n",
    "client_info = pd.read_parquet('nus_client_info_df.parquet')\n",
    "policy_info = pd.read_parquet('nus_policy_info_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secuityno</th>\n",
       "      <th>cltsex</th>\n",
       "      <th>cltdob</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>cltpcode</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>family_size</th>\n",
       "      <th>household_size_grp</th>\n",
       "      <th>family_size_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIN:14264</td>\n",
       "      <td>F</td>\n",
       "      <td>1993-02-17</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>545686</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS3_40to60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIN:7188</td>\n",
       "      <td>F</td>\n",
       "      <td>1977-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>308364</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>HH2_40to80</td>\n",
       "      <td>FS5_80up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIN:13608</td>\n",
       "      <td>F</td>\n",
       "      <td>1998-02-12</td>\n",
       "      <td>S</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>387393</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>HH1_lt40</td>\n",
       "      <td>FS2_20to40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIN:5087</td>\n",
       "      <td>F</td>\n",
       "      <td>1972-10-25</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>640469</td>\n",
       "      <td>84</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>HH3_80to100</td>\n",
       "      <td>FS2_20to40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIN:18531</td>\n",
       "      <td>M</td>\n",
       "      <td>1984-12-27</td>\n",
       "      <td>M</td>\n",
       "      <td>Others</td>\n",
       "      <td>763318</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>HH3_80to100</td>\n",
       "      <td>FS4_60to80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secuityno cltsex     cltdob marryd race_desc_map cltpcode household_size  \\\n",
       "0  CIN:14264      F 1993-02-17      M       Chinese   545686              1   \n",
       "1   CIN:7188      F 1977-06-15      M       Chinese   308364             72   \n",
       "2  CIN:13608      F 1998-02-12      S       Chinese   387393             28   \n",
       "3   CIN:5087      F 1972-10-25      M       Chinese   640469             84   \n",
       "4  CIN:18531      M 1984-12-27      M        Others   763318             92   \n",
       "\n",
       "  economic_status family_size household_size_grp family_size_grp  \n",
       "0              76          56           HH1_lt40      FS3_40to60  \n",
       "1              96          90         HH2_40to80        FS5_80up  \n",
       "2              93          23           HH1_lt40      FS2_20to40  \n",
       "3              51          34        HH3_80to100      FS2_20to40  \n",
       "4              18          73        HH3_80to100      FS4_60to80  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(client_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chdrnum</th>\n",
       "      <th>agntnum</th>\n",
       "      <th>secuityno</th>\n",
       "      <th>occdate</th>\n",
       "      <th>annual_premium</th>\n",
       "      <th>product</th>\n",
       "      <th>flg_main</th>\n",
       "      <th>flg_rider</th>\n",
       "      <th>flg_inforce</th>\n",
       "      <th>flg_lapsed</th>\n",
       "      <th>flg_cancel</th>\n",
       "      <th>flg_expire</th>\n",
       "      <th>flg_converted</th>\n",
       "      <th>product_grp</th>\n",
       "      <th>cust_age_at_purchase_grp</th>\n",
       "      <th>cust_tenure_at_purchase_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID:281</td>\n",
       "      <td>AIN:62</td>\n",
       "      <td>CIN:6957</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG05_35to39</td>\n",
       "      <td>TNR2_lt1yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID:280</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:2161</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG04_30to34</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID:2577</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>423.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID:2578</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:16605</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>217.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PID:305</td>\n",
       "      <td>AIN:63</td>\n",
       "      <td>CIN:7917</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>432.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG07_45to49</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chdrnum agntnum  secuityno    occdate  annual_premium product  flg_main  \\\n",
       "0   PID:281  AIN:62   CIN:6957 2018-11-12             0.0  prod_8         1   \n",
       "1   PID:280  AIN:63   CIN:2161 2024-02-22             7.0  prod_8         1   \n",
       "2  PID:2577  AIN:63  CIN:16605 2024-08-28           423.0  prod_6         1   \n",
       "3  PID:2578  AIN:63  CIN:16605 2024-08-27           217.0  prod_6         1   \n",
       "4   PID:305  AIN:63   CIN:7917 2024-08-28           432.0  prod_6         1   \n",
       "\n",
       "   flg_rider  flg_inforce  flg_lapsed  flg_cancel  flg_expire  flg_converted  \\\n",
       "0          0            1           0           0           0              1   \n",
       "1          0            1           0           0           0              1   \n",
       "2          0            1           0           0           0              1   \n",
       "3          0            1           0           0           0              1   \n",
       "4          0            1           0           0           0              1   \n",
       "\n",
       "  product_grp cust_age_at_purchase_grp cust_tenure_at_purchase_grp  \n",
       "0        PG:0              AG05_35to39                  TNR2_lt1yr  \n",
       "1        PG:0              AG04_30to34                 TNR4_4to8yr  \n",
       "2        PG:0              AG08_50to54                  TNR5_8yrup  \n",
       "3        PG:0              AG08_50to54                  TNR5_8yrup  \n",
       "4        PG:0              AG07_45to49                 TNR4_4to8yr  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(policy_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agntnum</th>\n",
       "      <th>agent_age</th>\n",
       "      <th>agent_gender</th>\n",
       "      <th>agent_marital</th>\n",
       "      <th>agent_tenure</th>\n",
       "      <th>cnt_converted</th>\n",
       "      <th>annual_premium_cnvrt</th>\n",
       "      <th>pct_lapsed</th>\n",
       "      <th>pct_cancel</th>\n",
       "      <th>pct_inforce</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_AG03_25to29</th>\n",
       "      <th>pct_AG04_30to34</th>\n",
       "      <th>pct_AG05_35to39</th>\n",
       "      <th>pct_AG06_40to44</th>\n",
       "      <th>pct_AG07_45to49</th>\n",
       "      <th>pct_AG08_50to54</th>\n",
       "      <th>pct_AG09_55to59</th>\n",
       "      <th>pct_AG10_60up</th>\n",
       "      <th>cluster</th>\n",
       "      <th>agent_product_expertise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIN:9513</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.004900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>3</td>\n",
       "      <td>[prod_2, prod_6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIN:4310</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1.971080e+05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.083937</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.116162</td>\n",
       "      <td>0.184343</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>6</td>\n",
       "      <td>[prod_6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIN:4302</td>\n",
       "      <td>39.0</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.106351e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.711606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137163</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.177022</td>\n",
       "      <td>0.311841</td>\n",
       "      <td>0.106682</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>6</td>\n",
       "      <td>[prod_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIN:4996</td>\n",
       "      <td>57.0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>41.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.514724e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.584838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.128159</td>\n",
       "      <td>0.108303</td>\n",
       "      <td>0.234657</td>\n",
       "      <td>0.162455</td>\n",
       "      <td>0.135379</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>6</td>\n",
       "      <td>[prod_7, prod_9, prod_6, prod_0, prod_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIN:3457</td>\n",
       "      <td>38.0</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1.215380e+06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.640656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069508</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.215082</td>\n",
       "      <td>0.214426</td>\n",
       "      <td>0.108197</td>\n",
       "      <td>0.084590</td>\n",
       "      <td>0.043279</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>6</td>\n",
       "      <td>[prod_6, prod_8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    agntnum  agent_age agent_gender agent_marital  agent_tenure  \\\n",
       "0  AIN:9513       32.0            M             M          15.0   \n",
       "1  AIN:4310       40.0            M             M          18.0   \n",
       "2  AIN:4302       39.0            F             M          40.0   \n",
       "3  AIN:4996       57.0            F             D          41.0   \n",
       "4  AIN:3457       38.0            M             M          62.0   \n",
       "\n",
       "   cnt_converted  annual_premium_cnvrt  pct_lapsed  pct_cancel  pct_inforce  \\\n",
       "0           21.0          1.004900e+04         1.0    0.814954     0.000000   \n",
       "1          396.0          1.971080e+05         0.6    0.083937     0.429293   \n",
       "2          853.0          5.106351e+05         0.3    0.017406     0.711606   \n",
       "3          554.0          3.514724e+05         0.3    0.003623     0.584838   \n",
       "4         1525.0          1.215380e+06         0.3    0.017523     0.640656   \n",
       "\n",
       "   ...  pct_AG03_25to29  pct_AG04_30to34  pct_AG05_35to39  pct_AG06_40to44  \\\n",
       "0  ...         0.142857         0.000000         0.000000         0.000000   \n",
       "1  ...         0.131313         0.388889         0.116162         0.184343   \n",
       "2  ...         0.137163         0.144197         0.177022         0.311841   \n",
       "3  ...         0.009025         0.128159         0.108303         0.234657   \n",
       "4  ...         0.069508         0.201311         0.215082         0.214426   \n",
       "\n",
       "   pct_AG07_45to49  pct_AG08_50to54  pct_AG09_55to59  pct_AG10_60up  cluster  \\\n",
       "0         0.000000         0.238095         0.142857       0.238095        3   \n",
       "1         0.083333         0.020202         0.040404       0.010101        6   \n",
       "2         0.106682         0.036342         0.035170       0.010551        6   \n",
       "3         0.162455         0.135379         0.160650       0.037906        6   \n",
       "4         0.108197         0.084590         0.043279       0.015082        6   \n",
       "\n",
       "                    agent_product_expertise  \n",
       "0                          [prod_2, prod_6]  \n",
       "1                                  [prod_6]  \n",
       "2                                  [prod_4]  \n",
       "3  [prod_7, prod_9, prod_6, prod_0, prod_2]  \n",
       "4                          [prod_6, prod_8]  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(agent_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secuityno</th>\n",
       "      <th>cltsex</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>family_size</th>\n",
       "      <th>yob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIN:14264</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>1993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIN:7188</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIN:13608</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIN:5087</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>84</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>1972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIN:18531</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Others</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secuityno cltsex marryd race_desc_map household_size economic_status  \\\n",
       "0  CIN:14264      F      M       Chinese              1              76   \n",
       "1   CIN:7188      F      M       Chinese             72              96   \n",
       "2  CIN:13608      F      S       Chinese             28              93   \n",
       "3   CIN:5087      F      M       Chinese             84              51   \n",
       "4  CIN:18531      M      M        Others             92              18   \n",
       "\n",
       "  family_size     yob  \n",
       "0          56  1993.0  \n",
       "1          90  1977.0  \n",
       "2          23  1998.0  \n",
       "3          34  1972.0  \n",
       "4          73  1984.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_info['yob'] = client_info['cltdob'].dt.year\n",
    "client_info_dropped = client_info.drop(columns=[\"cltdob\", \"cltpcode\", \"household_size_grp\", \"family_size_grp\"])\n",
    "client_info_dropped = client_info_dropped[client_info_dropped['marryd'] != 'P']\n",
    "client_info_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agntnum</th>\n",
       "      <th>agent_age</th>\n",
       "      <th>agent_tenure</th>\n",
       "      <th>cnt_converted</th>\n",
       "      <th>annual_premium_cnvrt</th>\n",
       "      <th>pct_lapsed</th>\n",
       "      <th>pct_cancel</th>\n",
       "      <th>pct_inforce</th>\n",
       "      <th>pct_prod_0_cnvrt</th>\n",
       "      <th>pct_prod_1_cnvrt</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_7</th>\n",
       "      <th>prod_8</th>\n",
       "      <th>prod_9</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "      <th>U</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIN:9513</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.004900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.814954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIN:4310</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1.971080e+05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.083937</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIN:4302</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>5.106351e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.711606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIN:4996</td>\n",
       "      <td>57.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>3.514724e+05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.584838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIN:3457</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1.215380e+06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.640656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    agntnum  agent_age  agent_tenure  cnt_converted  annual_premium_cnvrt  \\\n",
       "0  AIN:9513       32.0          15.0           21.0          1.004900e+04   \n",
       "1  AIN:4310       40.0          18.0          396.0          1.971080e+05   \n",
       "2  AIN:4302       39.0          40.0          853.0          5.106351e+05   \n",
       "3  AIN:4996       57.0          41.0          554.0          3.514724e+05   \n",
       "4  AIN:3457       38.0          62.0         1525.0          1.215380e+06   \n",
       "\n",
       "   pct_lapsed  pct_cancel  pct_inforce  pct_prod_0_cnvrt  pct_prod_1_cnvrt  \\\n",
       "0         1.0    0.814954     0.000000               0.0               0.0   \n",
       "1         0.6    0.083937     0.429293               0.0               0.0   \n",
       "2         0.3    0.017406     0.711606               0.0               0.0   \n",
       "3         0.3    0.003623     0.584838               0.0               0.0   \n",
       "4         0.3    0.017523     0.640656               0.0               0.0   \n",
       "\n",
       "   ...  prod_7  prod_8  prod_9  gender_F  gender_M  D  M  S  U  W  \n",
       "0  ...       0       0       0         0         1  0  1  0  0  0  \n",
       "1  ...       0       0       0         0         1  0  1  0  0  0  \n",
       "2  ...       0       0       0         1         0  0  1  0  0  0  \n",
       "3  ...       1       0       1         1         0  1  0  0  0  0  \n",
       "4  ...       0       1       0         0         1  0  1  0  0  0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "agent_info = agent_info[agent_info['agent_gender'] != 'U']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_products = mlb.fit_transform(agent_info['agent_product_expertise'])\n",
    "df_encoded_products = pd.DataFrame(encoded_products, columns=mlb.classes_, dtype=object)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_genders = mlb.fit_transform(agent_info['agent_gender'])\n",
    "df_encoded_genders = pd.DataFrame(encoded_genders, columns=mlb.classes_, dtype=object)\n",
    "df_encoded_genders.rename(columns={'M':'gender_M','F':'gender_F'},inplace=True)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_marital = mlb.fit_transform(agent_info['agent_marital'])\n",
    "df_encoded_marital = pd.DataFrame(encoded_marital, columns=mlb.classes_, dtype=object)\n",
    "\n",
    "agent_info_encoded = pd.concat([agent_info, df_encoded_products, df_encoded_genders, df_encoded_marital], axis=1).drop(columns=['agent_product_expertise', 'pct_SX0_unknown', 'cluster','agent_gender','agent_marital'])\n",
    "\n",
    "agent_info_encoded.drop(columns=['pct_prod_0_cnvrt','pct_prod_1_cnvrt','pct_prod_2_cnvrt','pct_prod_3_cnvrt', 'pct_prod_4_cnvrt','pct_prod_5_cnvrt'])\n",
    "agent_info_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       annual_premium           yob     agent_age  agent_tenure  \\\n",
      "count    28933.000000  28933.000000  28933.000000  28933.000000   \n",
      "mean      1073.198993   1978.661148     39.545121     62.519787   \n",
      "std       4382.362989     10.670054      9.406474     56.920644   \n",
      "min          0.000000   1940.000000     22.000000      0.000000   \n",
      "25%          0.000000   1972.000000     33.000000     22.000000   \n",
      "50%        120.000000   1980.000000     37.000000     42.000000   \n",
      "75%        525.000000   1987.000000     44.000000     84.000000   \n",
      "max     300039.600000   2006.000000     87.000000    427.000000   \n",
      "\n",
      "       cnt_converted  annual_premium_cnvrt    pct_lapsed    pct_cancel  \\\n",
      "count   28933.000000          2.893300e+04  28933.000000  28933.000000   \n",
      "mean     1160.433381          6.479471e+05      0.249501      0.106535   \n",
      "std      2422.155661          1.913596e+06      0.289880      0.128704   \n",
      "min         1.000000          0.000000e+00      0.000000      0.000000   \n",
      "25%       118.000000          3.819440e+04      0.000000      0.017517   \n",
      "50%       372.000000          1.615752e+05      0.100000      0.071087   \n",
      "75%      1212.000000          5.535871e+05      0.300000      0.144450   \n",
      "max     44011.000000          3.538133e+07      1.000000      0.952801   \n",
      "\n",
      "        pct_inforce  pct_prod_0_cnvrt  ...  pct_AG02_20to24  pct_AG03_25to29  \\\n",
      "count  28933.000000      28933.000000  ...     28933.000000     28933.000000   \n",
      "mean       0.726719          0.000373  ...         0.043678         0.107467   \n",
      "std        0.299632          0.011729  ...         0.074656         0.131418   \n",
      "min        0.000000          0.000000  ...         0.000000         0.000000   \n",
      "25%        0.646667          0.000000  ...         0.000000         0.015432   \n",
      "50%        0.837963          0.000000  ...         0.019830         0.070423   \n",
      "75%        0.944549          0.000000  ...         0.054422         0.142857   \n",
      "max        1.000000          1.000000  ...         1.000000         1.000000   \n",
      "\n",
      "       pct_AG04_30to34  pct_AG05_35to39  pct_AG06_40to44  pct_AG07_45to49  \\\n",
      "count     28933.000000     28933.000000     28933.000000     28933.000000   \n",
      "mean          0.221831         0.167009         0.178389         0.106704   \n",
      "std           0.175783         0.129844         0.147342         0.100620   \n",
      "min           0.000000         0.000000         0.000000         0.000000   \n",
      "25%           0.095652         0.075244         0.083333         0.034956   \n",
      "50%           0.190977         0.150890         0.150371         0.091266   \n",
      "75%           0.302817         0.228175         0.237624         0.148148   \n",
      "max           1.000000         1.000000         1.000000         1.000000   \n",
      "\n",
      "       pct_AG08_50to54  pct_AG09_55to59  pct_AG10_60up  cust_age_at_purchase  \n",
      "count     28933.000000     28933.000000   28933.000000          28933.000000  \n",
      "mean          0.071215         0.049053       0.036715             41.576539  \n",
      "std           0.080822         0.068916       0.070463              9.991763  \n",
      "min           0.000000         0.000000       0.000000             13.000000  \n",
      "25%           0.013812         0.003086       0.000000             34.000000  \n",
      "50%           0.050847         0.025434       0.012478             40.000000  \n",
      "75%           0.101874         0.066059       0.038462             48.000000  \n",
      "max           1.000000         1.000000       1.000000             83.000000  \n",
      "\n",
      "[8 rows x 32 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_premium</th>\n",
       "      <th>product</th>\n",
       "      <th>product_grp</th>\n",
       "      <th>cust_age_at_purchase_grp</th>\n",
       "      <th>cust_tenure_at_purchase_grp</th>\n",
       "      <th>cltsex</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>...</th>\n",
       "      <th>prod_8</th>\n",
       "      <th>prod_9</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "      <th>U</th>\n",
       "      <th>W</th>\n",
       "      <th>cust_age_at_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG05_35to39</td>\n",
       "      <td>TNR2_lt1yr</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>prod_8</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG04_30to34</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG08_50to54</td>\n",
       "      <td>TNR5_8yrup</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>prod_6</td>\n",
       "      <td>PG:0</td>\n",
       "      <td>AG07_45to49</td>\n",
       "      <td>TNR4_4to8yr</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>Malay</td>\n",
       "      <td>23</td>\n",
       "      <td>00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   annual_premium product product_grp cust_age_at_purchase_grp  \\\n",
       "0             0.0  prod_8        PG:0              AG05_35to39   \n",
       "1             7.0  prod_8        PG:0              AG04_30to34   \n",
       "2           423.0  prod_6        PG:0              AG08_50to54   \n",
       "3           217.0  prod_6        PG:0              AG08_50to54   \n",
       "4           432.0  prod_6        PG:0              AG07_45to49   \n",
       "\n",
       "  cust_tenure_at_purchase_grp cltsex marryd race_desc_map household_size  \\\n",
       "0                  TNR2_lt1yr      F      M       Chinese             25   \n",
       "1                 TNR4_4to8yr      M      S       Chinese             57   \n",
       "2                  TNR5_8yrup      M      M       Chinese             56   \n",
       "3                  TNR5_8yrup      M      M       Chinese             56   \n",
       "4                 TNR4_4to8yr      F      M         Malay             23   \n",
       "\n",
       "  economic_status  ... prod_8  prod_9  gender_F  gender_M  D  M  S  U  W  \\\n",
       "0              78  ...      0       1         0         1  0  0  1  0  0   \n",
       "1              31  ...      0       1         0         1  0  0  1  0  0   \n",
       "2              30  ...      0       1         0         1  0  0  1  0  0   \n",
       "3              30  ...      0       1         0         1  0  0  1  0  0   \n",
       "4              00  ...      0       1         0         1  0  0  1  0  0   \n",
       "\n",
       "   cust_age_at_purchase  \n",
       "0                  36.0  \n",
       "1                  33.0  \n",
       "2                  51.0  \n",
       "3                  51.0  \n",
       "4                  46.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = policy_info.merge(client_info_dropped, on=\"secuityno\").merge(agent_info_encoded, on=\"agntnum\")\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "merged_df[\"cust_age_at_purchase\"] = merged_df[\"occdate\"].dt.year - merged_df[\"yob\"]\n",
    "\n",
    "merged_df = merged_df.drop(columns=[\"chdrnum\", \"secuityno\", \"agntnum\",\"occdate\", \"flg_main\", \"flg_rider\", \"flg_cancel\", \"flg_converted\", \"flg_inforce\", \"flg_expire\", \"flg_lapsed\"])\n",
    "print(merged_df.describe())\n",
    "\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        agent_age  agent_tenure  cnt_converted  annual_premium_cnvrt  \\\n",
       "0           31.0           6.0           47.0              6112.000   \n",
       "1           32.0          71.0         4560.0           1045929.756   \n",
       "2           32.0          71.0         4560.0           1045929.756   \n",
       "3           32.0          71.0         4560.0           1045929.756   \n",
       "4           32.0          71.0         4560.0           1045929.756   \n",
       "...          ...           ...            ...                   ...   \n",
       "29480       39.0          24.0          476.0            569045.700   \n",
       "29481       52.0           7.0           32.0             13780.000   \n",
       "29482       70.0         216.0          195.0             98906.500   \n",
       "29483       48.0          28.0           19.0             10779.000   \n",
       "29484       34.0          13.0            1.0               701.000   \n",
       "\n",
       "       pct_lapsed  pct_cancel  pct_inforce  pct_prod_0_cnvrt  \\\n",
       "0             0.1    0.243689     0.936170          0.000000   \n",
       "1             0.1    0.157312     0.854605          0.000000   \n",
       "2             0.1    0.157312     0.854605          0.000000   \n",
       "3             0.1    0.157312     0.854605          0.000000   \n",
       "4             0.1    0.157312     0.854605          0.000000   \n",
       "...           ...         ...          ...               ...   \n",
       "29480         0.3    0.016649     0.310924          0.000000   \n",
       "29481         0.8    0.030523     0.156250          0.000000   \n",
       "29482         0.3    0.000000     0.661538          0.033136   \n",
       "29483         0.2    0.050362     0.789474          0.000000   \n",
       "29484         1.0    0.000000     0.000000          0.000000   \n",
       "\n",
       "       pct_prod_1_cnvrt  pct_prod_2_cnvrt  ...  prod_7  prod_8  prod_9  \\\n",
       "0              0.212766          0.319149  ...       0       0       1   \n",
       "1              0.041009          0.051974  ...       0       0       1   \n",
       "2              0.041009          0.051974  ...       0       0       1   \n",
       "3              0.041009          0.051974  ...       0       0       1   \n",
       "4              0.041009          0.051974  ...       0       0       1   \n",
       "...                 ...               ...  ...     ...     ...     ...   \n",
       "29480          0.000000          0.000000  ...       1       1       0   \n",
       "29481          0.000000          0.375000  ...       1       0       0   \n",
       "29482          0.000000          0.000000  ...       1       1       1   \n",
       "29483          0.000000          0.157895  ...       0       1       1   \n",
       "29484          0.000000          0.000000  ...       1       1       0   \n",
       "\n",
       "       gender_F  gender_M  D  M  S  U  W  \n",
       "0             0         1  0  0  1  0  0  \n",
       "1             0         1  0  0  1  0  0  \n",
       "2             0         1  0  0  1  0  0  \n",
       "3             0         1  0  0  1  0  0  \n",
       "4             0         1  0  0  1  0  0  \n",
       "...         ...       ... .. .. .. .. ..  \n",
       "29480         0         1  0  1  0  0  0  \n",
       "29481         1         0  0  1  0  0  0  \n",
       "29482         1         0  0  1  0  0  0  \n",
       "29483         0         1  0  0  1  0  0  \n",
       "29484         1         0  0  0  1  0  0  \n",
       "\n",
       "[28933 rows x 43 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cltsex</th>\n",
       "      <th>marryd</th>\n",
       "      <th>race_desc_map</th>\n",
       "      <th>household_size</th>\n",
       "      <th>economic_status</th>\n",
       "      <th>family_size</th>\n",
       "      <th>cust_age_at_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>78</td>\n",
       "      <td>98</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cltsex  marryd  race_desc_map  household_size  economic_status  \\\n",
       "0       0       1              0             167               78   \n",
       "1       1       2              0             301               31   \n",
       "2       1       1              0             300               30   \n",
       "3       1       1              0             300               30   \n",
       "4       0       1              2             146                0   \n",
       "\n",
       "   family_size  cust_age_at_purchase  \n",
       "0           98                  36.0  \n",
       "1           47                  33.0  \n",
       "2           60                  51.0  \n",
       "3           60                  51.0  \n",
       "4           55                  46.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_0</th>\n",
       "      <th>prod_2</th>\n",
       "      <th>prod_4</th>\n",
       "      <th>prod_6</th>\n",
       "      <th>prod_7</th>\n",
       "      <th>prod_8</th>\n",
       "      <th>prod_9</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "      <th>U</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prod_0  prod_2  prod_4  prod_6  prod_7  prod_8  prod_9  gender_F  gender_M  \\\n",
       "0       1       1       0       0       0       0       1         0         1   \n",
       "1       1       0       1       1       0       0       1         0         1   \n",
       "2       1       0       1       1       0       0       1         0         1   \n",
       "3       1       0       1       1       0       0       1         0         1   \n",
       "4       1       0       1       1       0       0       1         0         1   \n",
       "\n",
       "   D  M  S  U  W  \n",
       "0  0  0  1  0  0  \n",
       "1  0  0  1  0  0  \n",
       "2  0  0  1  0  0  \n",
       "3  0  0  1  0  0  \n",
       "4  0  0  1  0  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "client_features = list(client_info_dropped.columns.drop(['secuityno', 'yob']))\n",
    "client_features.append('cust_age_at_purchase')\n",
    "#agent_targets = agent_info.columns.drop(['agntnum', 'agent_product_expertise', 'pct_SX0_unknown', 'cluster'])\n",
    "agent_targets = agent_info_encoded.columns.drop(['agntnum'])\n",
    "\n",
    "X = merged_df[client_features]\n",
    "y = merged_df[agent_targets]\n",
    "display(y.head)\n",
    "\n",
    "#X_classification_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "#X_regression_columns = X.select_dtypes(include=['number']).columns\n",
    "y_classification_columns = y.select_dtypes(include=['object', 'category']).columns\n",
    "#y_classification_columns = ['prod_0','prod_2','prod_4','prod_6','prod_7','prod_8','prod_9','gender_F','gender_M','D','M','S','U','W']\n",
    "y_regression_columns = y.select_dtypes(include=['number']).columns\n",
    "\n",
    "#X_classification = X[X_classification_columns]\n",
    "#X_regression = X[X_regression_columns]\n",
    "y_classification = y[y_classification_columns]\n",
    "y_regression = y[y_regression_columns]\n",
    "\n",
    "X_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    X[col] = X_encoder.fit_transform(X[col])\n",
    "display(X.head())\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "\n",
    "y_encoder = LabelEncoder()\n",
    "for col in y_classification.select_dtypes(include=[\"object\"]).columns:\n",
    "    y_classification[col] = y_encoder.fit_transform(y_classification[col])\n",
    "display(y_classification.head())\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_regression = y_scaler.fit_transform(y_regression) # classification only or regression too?\n",
    "# just look at classification\n",
    "\n",
    "# 70% training data, 10% validation data, 20% test data\n",
    "X_c_train, X_c_temp, y_c_train_all, y_c_temp_all = skl.model_selection.train_test_split(X, y_classification, test_size=0.3, \n",
    "                                                                                        random_state=seed)\n",
    "X_c_val, X_c_test, y_c_val_all, y_c_test_all = skl.model_selection.train_test_split(X_c_temp, y_c_temp_all, test_size=2/3, random_state=seed)\n",
    "X_r_train, X_r_temp, y_r_train_all, y_r_temp_all = skl.model_selection.train_test_split(X, y_regression, test_size=0.3, random_state=seed)\n",
    "X_r_val, X_r_test, y_r_val_all, y_r_test_all = skl.model_selection.train_test_split(X_r_temp, y_r_temp_all, test_size=2/3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                val_loss += criterion(y_pred, y_batch).item()\n",
    "            model.train()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss/len(train_loader):.4f} - Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPredictionRegNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AgentPredictionRegNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),  # Normalise activations\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, 32),\n",
    "            nn.LeakyReLU(0.01),\n",
    "\n",
    "            nn.Linear(32, 1)  # For regression (Remove activation here)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AgentPredictionRegNN(input_dim=X.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.02, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0349 - Val Loss: 1.0408\n",
      "Epoch 2/10 - Train Loss: 1.0351 - Val Loss: 1.0407\n",
      "Epoch 3/10 - Train Loss: 1.0339 - Val Loss: 1.0414\n",
      "Epoch 4/10 - Train Loss: 1.0348 - Val Loss: 1.0413\n",
      "Epoch 5/10 - Train Loss: 1.0337 - Val Loss: 1.0415\n",
      "Epoch 6/10 - Train Loss: 1.0356 - Val Loss: 1.0406\n",
      "Epoch 7/10 - Train Loss: 1.0350 - Val Loss: 1.0409\n",
      "Epoch 8/10 - Train Loss: 1.0353 - Val Loss: 1.0411\n",
      "Epoch 9/10 - Train Loss: 1.0354 - Val Loss: 1.0410\n",
      "Epoch 10/10 - Train Loss: 1.0350 - Val Loss: 1.0421\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0529 - Val Loss: 0.9669\n",
      "Epoch 2/10 - Train Loss: 1.0518 - Val Loss: 0.9661\n",
      "Epoch 3/10 - Train Loss: 1.0508 - Val Loss: 0.9680\n",
      "Epoch 4/10 - Train Loss: 1.0520 - Val Loss: 0.9640\n",
      "Epoch 5/10 - Train Loss: 1.0501 - Val Loss: 0.9673\n",
      "Epoch 6/10 - Train Loss: 1.0526 - Val Loss: 0.9684\n",
      "Epoch 7/10 - Train Loss: 1.0513 - Val Loss: 0.9656\n",
      "Epoch 8/10 - Train Loss: 1.0500 - Val Loss: 0.9639\n",
      "Epoch 9/10 - Train Loss: 1.0527 - Val Loss: 0.9654\n",
      "Epoch 10/10 - Train Loss: 1.0509 - Val Loss: 0.9671\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 0.9972 - Val Loss: 1.1589\n",
      "Epoch 2/10 - Train Loss: 0.9963 - Val Loss: 1.1596\n",
      "Epoch 3/10 - Train Loss: 0.9966 - Val Loss: 1.1609\n",
      "Epoch 4/10 - Train Loss: 0.9958 - Val Loss: 1.1612\n",
      "Epoch 5/10 - Train Loss: 0.9968 - Val Loss: 1.1593\n",
      "Epoch 6/10 - Train Loss: 0.9958 - Val Loss: 1.1594\n",
      "Epoch 7/10 - Train Loss: 0.9955 - Val Loss: 1.1597\n",
      "Epoch 8/10 - Train Loss: 0.9964 - Val Loss: 1.1590\n",
      "Epoch 9/10 - Train Loss: 0.9967 - Val Loss: 1.1604\n",
      "Epoch 10/10 - Train Loss: 0.9965 - Val Loss: 1.1602\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0294 - Val Loss: 1.1912\n",
      "Epoch 2/10 - Train Loss: 1.0272 - Val Loss: 1.1913\n",
      "Epoch 3/10 - Train Loss: 1.0311 - Val Loss: 1.1910\n",
      "Epoch 4/10 - Train Loss: 1.0284 - Val Loss: 1.1914\n",
      "Epoch 5/10 - Train Loss: 1.0294 - Val Loss: 1.1929\n",
      "Epoch 6/10 - Train Loss: 1.0296 - Val Loss: 1.1945\n",
      "Epoch 7/10 - Train Loss: 1.0286 - Val Loss: 1.1922\n",
      "Epoch 8/10 - Train Loss: 1.0308 - Val Loss: 1.1914\n",
      "Epoch 9/10 - Train Loss: 1.0297 - Val Loss: 1.1946\n",
      "Epoch 10/10 - Train Loss: 1.0322 - Val Loss: 1.1941\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0572 - Val Loss: 0.9639\n",
      "Epoch 2/10 - Train Loss: 1.0584 - Val Loss: 0.9634\n",
      "Epoch 3/10 - Train Loss: 1.0572 - Val Loss: 0.9637\n",
      "Epoch 4/10 - Train Loss: 1.0567 - Val Loss: 0.9621\n",
      "Epoch 5/10 - Train Loss: 1.0570 - Val Loss: 0.9646\n",
      "Epoch 6/10 - Train Loss: 1.0562 - Val Loss: 0.9631\n",
      "Epoch 7/10 - Train Loss: 1.0569 - Val Loss: 0.9638\n",
      "Epoch 8/10 - Train Loss: 1.0568 - Val Loss: 0.9642\n",
      "Epoch 9/10 - Train Loss: 1.0564 - Val Loss: 0.9650\n",
      "Epoch 10/10 - Train Loss: 1.0570 - Val Loss: 0.9645\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0463 - Val Loss: 0.9499\n",
      "Epoch 2/10 - Train Loss: 1.0476 - Val Loss: 0.9494\n",
      "Epoch 3/10 - Train Loss: 1.0455 - Val Loss: 0.9494\n",
      "Epoch 4/10 - Train Loss: 1.0455 - Val Loss: 0.9481\n",
      "Epoch 5/10 - Train Loss: 1.0465 - Val Loss: 0.9486\n",
      "Epoch 6/10 - Train Loss: 1.0463 - Val Loss: 0.9477\n",
      "Epoch 7/10 - Train Loss: 1.0479 - Val Loss: 0.9494\n",
      "Epoch 8/10 - Train Loss: 1.0449 - Val Loss: 0.9500\n",
      "Epoch 9/10 - Train Loss: 1.0466 - Val Loss: 0.9502\n",
      "Epoch 10/10 - Train Loss: 1.0471 - Val Loss: 0.9490\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0709 - Val Loss: 0.9902\n",
      "Epoch 2/10 - Train Loss: 1.0704 - Val Loss: 0.9914\n",
      "Epoch 3/10 - Train Loss: 1.0707 - Val Loss: 0.9967\n",
      "Epoch 4/10 - Train Loss: 1.0722 - Val Loss: 0.9936\n",
      "Epoch 5/10 - Train Loss: 1.0714 - Val Loss: 0.9917\n",
      "Epoch 6/10 - Train Loss: 1.0711 - Val Loss: 0.9941\n",
      "Epoch 7/10 - Train Loss: 1.0704 - Val Loss: 0.9907\n",
      "Epoch 8/10 - Train Loss: 1.0699 - Val Loss: 0.9993\n",
      "Epoch 9/10 - Train Loss: 1.0707 - Val Loss: 0.9961\n",
      "Epoch 10/10 - Train Loss: 1.0724 - Val Loss: 0.9914\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0321 - Val Loss: 1.7020\n",
      "Epoch 2/10 - Train Loss: 1.0317 - Val Loss: 1.7022\n",
      "Epoch 3/10 - Train Loss: 1.0317 - Val Loss: 1.7018\n",
      "Epoch 4/10 - Train Loss: 1.0324 - Val Loss: 1.7003\n",
      "Epoch 5/10 - Train Loss: 1.0318 - Val Loss: 1.7023\n",
      "Epoch 6/10 - Train Loss: 1.0316 - Val Loss: 1.7012\n",
      "Epoch 7/10 - Train Loss: 1.0308 - Val Loss: 1.7003\n",
      "Epoch 8/10 - Train Loss: 1.0315 - Val Loss: 1.7029\n",
      "Epoch 9/10 - Train Loss: 1.0315 - Val Loss: 1.7014\n",
      "Epoch 10/10 - Train Loss: 1.0314 - Val Loss: 1.7016\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0715 - Val Loss: 0.9190\n",
      "Epoch 2/10 - Train Loss: 1.0713 - Val Loss: 0.9195\n",
      "Epoch 3/10 - Train Loss: 1.0709 - Val Loss: 0.9197\n",
      "Epoch 4/10 - Train Loss: 1.0718 - Val Loss: 0.9197\n",
      "Epoch 5/10 - Train Loss: 1.0703 - Val Loss: 0.9189\n",
      "Epoch 6/10 - Train Loss: 1.0708 - Val Loss: 0.9195\n",
      "Epoch 7/10 - Train Loss: 1.0721 - Val Loss: 0.9207\n",
      "Epoch 8/10 - Train Loss: 1.0706 - Val Loss: 0.9194\n",
      "Epoch 9/10 - Train Loss: 1.0715 - Val Loss: 0.9211\n",
      "Epoch 10/10 - Train Loss: 1.0719 - Val Loss: 0.9186\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.1488 - Val Loss: 0.9644\n",
      "Epoch 2/10 - Train Loss: 1.1505 - Val Loss: 0.9662\n",
      "Epoch 3/10 - Train Loss: 1.1496 - Val Loss: 0.9655\n",
      "Epoch 4/10 - Train Loss: 1.1488 - Val Loss: 0.9620\n",
      "Epoch 5/10 - Train Loss: 1.1494 - Val Loss: 0.9632\n",
      "Epoch 6/10 - Train Loss: 1.1503 - Val Loss: 0.9628\n",
      "Epoch 7/10 - Train Loss: 1.1495 - Val Loss: 0.9638\n",
      "Epoch 8/10 - Train Loss: 1.1497 - Val Loss: 0.9629\n",
      "Epoch 9/10 - Train Loss: 1.1490 - Val Loss: 0.9639\n",
      "Epoch 10/10 - Train Loss: 1.1498 - Val Loss: 0.9642\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.2271 - Val Loss: 0.8403\n",
      "Epoch 2/10 - Train Loss: 1.2266 - Val Loss: 0.8326\n",
      "Epoch 3/10 - Train Loss: 1.2296 - Val Loss: 0.8414\n",
      "Epoch 4/10 - Train Loss: 1.2280 - Val Loss: 0.8431\n",
      "Epoch 5/10 - Train Loss: 1.2451 - Val Loss: 0.8291\n",
      "Epoch 6/10 - Train Loss: 1.2253 - Val Loss: 0.8342\n",
      "Epoch 7/10 - Train Loss: 1.2284 - Val Loss: 0.8390\n",
      "Epoch 8/10 - Train Loss: 1.2298 - Val Loss: 0.8349\n",
      "Epoch 9/10 - Train Loss: 1.2263 - Val Loss: 0.8284\n",
      "Epoch 10/10 - Train Loss: 1.2264 - Val Loss: 0.8377\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.1067 - Val Loss: 1.1707\n",
      "Epoch 2/10 - Train Loss: 1.1071 - Val Loss: 1.1741\n",
      "Epoch 3/10 - Train Loss: 1.1046 - Val Loss: 1.1733\n",
      "Epoch 4/10 - Train Loss: 1.1050 - Val Loss: 1.1730\n",
      "Epoch 5/10 - Train Loss: 1.1063 - Val Loss: 1.1698\n",
      "Epoch 6/10 - Train Loss: 1.1080 - Val Loss: 1.1726\n",
      "Epoch 7/10 - Train Loss: 1.1051 - Val Loss: 1.1610\n",
      "Epoch 8/10 - Train Loss: 1.1054 - Val Loss: 1.1708\n",
      "Epoch 9/10 - Train Loss: 1.1080 - Val Loss: 1.1795\n",
      "Epoch 10/10 - Train Loss: 1.1061 - Val Loss: 1.1643\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0939 - Val Loss: 0.9916\n",
      "Epoch 2/10 - Train Loss: 1.0868 - Val Loss: 0.9928\n",
      "Epoch 3/10 - Train Loss: 1.0859 - Val Loss: 0.9872\n",
      "Epoch 4/10 - Train Loss: 1.0871 - Val Loss: 0.9892\n",
      "Epoch 5/10 - Train Loss: 1.0950 - Val Loss: 0.9863\n",
      "Epoch 6/10 - Train Loss: 1.0857 - Val Loss: 0.9869\n",
      "Epoch 7/10 - Train Loss: 1.0864 - Val Loss: 0.9882\n",
      "Epoch 8/10 - Train Loss: 1.0872 - Val Loss: 0.9895\n",
      "Epoch 9/10 - Train Loss: 1.0871 - Val Loss: 0.9881\n",
      "Epoch 10/10 - Train Loss: 1.0865 - Val Loss: 0.9890\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0940 - Val Loss: 1.0030\n",
      "Epoch 2/10 - Train Loss: 1.0929 - Val Loss: 1.0013\n",
      "Epoch 3/10 - Train Loss: 1.0927 - Val Loss: 1.0039\n",
      "Epoch 4/10 - Train Loss: 1.0946 - Val Loss: 1.0014\n",
      "Epoch 5/10 - Train Loss: 1.0933 - Val Loss: 1.0054\n",
      "Epoch 6/10 - Train Loss: 1.0922 - Val Loss: 1.0028\n",
      "Epoch 7/10 - Train Loss: 1.0938 - Val Loss: 1.0017\n",
      "Epoch 8/10 - Train Loss: 1.0924 - Val Loss: 1.0030\n",
      "Epoch 9/10 - Train Loss: 1.0937 - Val Loss: 1.0029\n",
      "Epoch 10/10 - Train Loss: 1.0941 - Val Loss: 1.0027\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.0953 - Val Loss: 0.7238\n",
      "Epoch 2/10 - Train Loss: 1.0760 - Val Loss: 0.7235\n",
      "Epoch 3/10 - Train Loss: 1.0747 - Val Loss: 0.7254\n",
      "Epoch 4/10 - Train Loss: 1.0761 - Val Loss: 0.7238\n",
      "Epoch 5/10 - Train Loss: 1.0759 - Val Loss: 0.7243\n",
      "Epoch 6/10 - Train Loss: 1.0759 - Val Loss: 0.7235\n",
      "Epoch 7/10 - Train Loss: 1.0790 - Val Loss: 0.7253\n",
      "Epoch 8/10 - Train Loss: 1.0759 - Val Loss: 0.7238\n",
      "Epoch 9/10 - Train Loss: 1.0855 - Val Loss: 0.7253\n",
      "Epoch 10/10 - Train Loss: 1.0759 - Val Loss: 0.7228\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0458 - Val Loss: 1.0397\n",
      "Epoch 2/10 - Train Loss: 1.0459 - Val Loss: 1.0453\n",
      "Epoch 3/10 - Train Loss: 1.0461 - Val Loss: 1.0440\n",
      "Epoch 4/10 - Train Loss: 1.0457 - Val Loss: 1.0420\n",
      "Epoch 5/10 - Train Loss: 1.0466 - Val Loss: 1.0449\n",
      "Epoch 6/10 - Train Loss: 1.0457 - Val Loss: 1.0460\n",
      "Epoch 7/10 - Train Loss: 1.0448 - Val Loss: 1.0450\n",
      "Epoch 8/10 - Train Loss: 1.0453 - Val Loss: 1.0453\n",
      "Epoch 9/10 - Train Loss: 1.0449 - Val Loss: 1.0439\n",
      "Epoch 10/10 - Train Loss: 1.0454 - Val Loss: 1.0468\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0370 - Val Loss: 1.0390\n",
      "Epoch 2/10 - Train Loss: 1.0377 - Val Loss: 1.0377\n",
      "Epoch 3/10 - Train Loss: 1.0361 - Val Loss: 1.0397\n",
      "Epoch 4/10 - Train Loss: 1.0371 - Val Loss: 1.0394\n",
      "Epoch 5/10 - Train Loss: 1.0373 - Val Loss: 1.0392\n",
      "Epoch 6/10 - Train Loss: 1.0369 - Val Loss: 1.0380\n",
      "Epoch 7/10 - Train Loss: 1.0370 - Val Loss: 1.0393\n",
      "Epoch 8/10 - Train Loss: 1.0365 - Val Loss: 1.0396\n",
      "Epoch 9/10 - Train Loss: 1.0371 - Val Loss: 1.0393\n",
      "Epoch 10/10 - Train Loss: 1.0366 - Val Loss: 1.0395\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0377 - Val Loss: 0.9866\n",
      "Epoch 2/10 - Train Loss: 1.0385 - Val Loss: 0.9871\n",
      "Epoch 3/10 - Train Loss: 1.0390 - Val Loss: 0.9868\n",
      "Epoch 4/10 - Train Loss: 1.0385 - Val Loss: 0.9868\n",
      "Epoch 5/10 - Train Loss: 1.0384 - Val Loss: 0.9875\n",
      "Epoch 6/10 - Train Loss: 1.0377 - Val Loss: 0.9870\n",
      "Epoch 7/10 - Train Loss: 1.0396 - Val Loss: 0.9877\n",
      "Epoch 8/10 - Train Loss: 1.0393 - Val Loss: 0.9872\n",
      "Epoch 9/10 - Train Loss: 1.0378 - Val Loss: 0.9876\n",
      "Epoch 10/10 - Train Loss: 1.0389 - Val Loss: 0.9875\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.1432 - Val Loss: 1.0772\n",
      "Epoch 2/10 - Train Loss: 1.1423 - Val Loss: 1.0791\n",
      "Epoch 3/10 - Train Loss: 1.1447 - Val Loss: 1.0742\n",
      "Epoch 4/10 - Train Loss: 1.1421 - Val Loss: 1.0834\n",
      "Epoch 5/10 - Train Loss: 1.1436 - Val Loss: 1.0772\n",
      "Epoch 6/10 - Train Loss: 1.1451 - Val Loss: 1.0728\n",
      "Epoch 7/10 - Train Loss: 1.1440 - Val Loss: 1.0787\n",
      "Epoch 8/10 - Train Loss: 1.1438 - Val Loss: 1.0731\n",
      "Epoch 9/10 - Train Loss: 1.1434 - Val Loss: 1.0735\n",
      "Epoch 10/10 - Train Loss: 1.1431 - Val Loss: 1.0808\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.2156 - Val Loss: 0.8971\n",
      "Epoch 2/10 - Train Loss: 1.2164 - Val Loss: 0.8894\n",
      "Epoch 3/10 - Train Loss: 1.2138 - Val Loss: 0.8925\n",
      "Epoch 4/10 - Train Loss: 1.2147 - Val Loss: 0.8946\n",
      "Epoch 5/10 - Train Loss: 1.2148 - Val Loss: 0.8956\n",
      "Epoch 6/10 - Train Loss: 1.2147 - Val Loss: 0.8981\n",
      "Epoch 7/10 - Train Loss: 1.2167 - Val Loss: 0.8886\n",
      "Epoch 8/10 - Train Loss: 1.2169 - Val Loss: 0.8930\n",
      "Epoch 9/10 - Train Loss: 1.2147 - Val Loss: 0.8897\n",
      "Epoch 10/10 - Train Loss: 1.2139 - Val Loss: 0.8977\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0575 - Val Loss: 1.0941\n",
      "Epoch 2/10 - Train Loss: 1.0570 - Val Loss: 1.0939\n",
      "Epoch 3/10 - Train Loss: 1.0610 - Val Loss: 1.0949\n",
      "Epoch 4/10 - Train Loss: 1.0575 - Val Loss: 1.0939\n",
      "Epoch 5/10 - Train Loss: 1.0578 - Val Loss: 1.0946\n",
      "Epoch 6/10 - Train Loss: 1.0578 - Val Loss: 1.0947\n",
      "Epoch 7/10 - Train Loss: 1.0585 - Val Loss: 1.0948\n",
      "Epoch 8/10 - Train Loss: 1.0578 - Val Loss: 1.0944\n",
      "Epoch 9/10 - Train Loss: 1.0571 - Val Loss: 1.0935\n",
      "Epoch 10/10 - Train Loss: 1.0567 - Val Loss: 1.0938\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0590 - Val Loss: 0.8855\n",
      "Epoch 2/10 - Train Loss: 1.0588 - Val Loss: 0.8865\n",
      "Epoch 3/10 - Train Loss: 1.0587 - Val Loss: 0.8854\n",
      "Epoch 4/10 - Train Loss: 1.0598 - Val Loss: 0.8862\n",
      "Epoch 5/10 - Train Loss: 1.0584 - Val Loss: 0.8847\n",
      "Epoch 6/10 - Train Loss: 1.0587 - Val Loss: 0.8850\n",
      "Epoch 7/10 - Train Loss: 1.0583 - Val Loss: 0.8867\n",
      "Epoch 8/10 - Train Loss: 1.0609 - Val Loss: 0.8861\n",
      "Epoch 9/10 - Train Loss: 1.0598 - Val Loss: 0.8866\n",
      "Epoch 10/10 - Train Loss: 1.0593 - Val Loss: 0.8863\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0303 - Val Loss: 1.0066\n",
      "Epoch 2/10 - Train Loss: 1.0308 - Val Loss: 1.0060\n",
      "Epoch 3/10 - Train Loss: 1.0308 - Val Loss: 1.0061\n",
      "Epoch 4/10 - Train Loss: 1.0316 - Val Loss: 1.0060\n",
      "Epoch 5/10 - Train Loss: 1.0306 - Val Loss: 1.0062\n",
      "Epoch 6/10 - Train Loss: 1.0315 - Val Loss: 1.0081\n",
      "Epoch 7/10 - Train Loss: 1.0307 - Val Loss: 1.0064\n",
      "Epoch 8/10 - Train Loss: 1.0313 - Val Loss: 1.0062\n",
      "Epoch 9/10 - Train Loss: 1.0308 - Val Loss: 1.0061\n",
      "Epoch 10/10 - Train Loss: 1.0319 - Val Loss: 1.0061\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0505 - Val Loss: 1.0607\n",
      "Epoch 2/10 - Train Loss: 1.0507 - Val Loss: 1.0626\n",
      "Epoch 3/10 - Train Loss: 1.0510 - Val Loss: 1.0596\n",
      "Epoch 4/10 - Train Loss: 1.0497 - Val Loss: 1.0598\n",
      "Epoch 5/10 - Train Loss: 1.0512 - Val Loss: 1.0593\n",
      "Epoch 6/10 - Train Loss: 1.0513 - Val Loss: 1.0622\n",
      "Epoch 7/10 - Train Loss: 1.0528 - Val Loss: 1.0595\n",
      "Epoch 8/10 - Train Loss: 1.0504 - Val Loss: 1.0594\n",
      "Epoch 9/10 - Train Loss: 1.0508 - Val Loss: 1.0622\n",
      "Epoch 10/10 - Train Loss: 1.0512 - Val Loss: 1.0618\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0310 - Val Loss: 0.9344\n",
      "Epoch 2/10 - Train Loss: 1.0308 - Val Loss: 0.9343\n",
      "Epoch 3/10 - Train Loss: 1.0302 - Val Loss: 0.9330\n",
      "Epoch 4/10 - Train Loss: 1.0294 - Val Loss: 0.9343\n",
      "Epoch 5/10 - Train Loss: 1.0307 - Val Loss: 0.9319\n",
      "Epoch 6/10 - Train Loss: 1.0298 - Val Loss: 0.9335\n",
      "Epoch 7/10 - Train Loss: 1.0314 - Val Loss: 0.9327\n",
      "Epoch 8/10 - Train Loss: 1.0317 - Val Loss: 0.9339\n",
      "Epoch 9/10 - Train Loss: 1.0310 - Val Loss: 0.9329\n",
      "Epoch 10/10 - Train Loss: 1.0301 - Val Loss: 0.9340\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0458 - Val Loss: 1.0948\n",
      "Epoch 2/10 - Train Loss: 1.0469 - Val Loss: 1.0948\n",
      "Epoch 3/10 - Train Loss: 1.0463 - Val Loss: 1.0953\n",
      "Epoch 4/10 - Train Loss: 1.0469 - Val Loss: 1.0955\n",
      "Epoch 5/10 - Train Loss: 1.0451 - Val Loss: 1.0954\n",
      "Epoch 6/10 - Train Loss: 1.0457 - Val Loss: 1.0955\n",
      "Epoch 7/10 - Train Loss: 1.0466 - Val Loss: 1.0945\n",
      "Epoch 8/10 - Train Loss: 1.0466 - Val Loss: 1.0958\n",
      "Epoch 9/10 - Train Loss: 1.0468 - Val Loss: 1.0952\n",
      "Epoch 10/10 - Train Loss: 1.0462 - Val Loss: 1.0948\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0500 - Val Loss: 1.0539\n",
      "Epoch 2/10 - Train Loss: 1.0479 - Val Loss: 1.0493\n",
      "Epoch 3/10 - Train Loss: 1.0496 - Val Loss: 1.0507\n",
      "Epoch 4/10 - Train Loss: 1.0494 - Val Loss: 1.0490\n",
      "Epoch 5/10 - Train Loss: 1.0488 - Val Loss: 1.0505\n",
      "Epoch 6/10 - Train Loss: 1.0488 - Val Loss: 1.0470\n",
      "Epoch 7/10 - Train Loss: 1.0485 - Val Loss: 1.0498\n",
      "Epoch 8/10 - Train Loss: 1.0491 - Val Loss: 1.0455\n",
      "Epoch 9/10 - Train Loss: 1.0491 - Val Loss: 1.0485\n",
      "Epoch 10/10 - Train Loss: 1.0496 - Val Loss: 1.0471\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0524 - Val Loss: 0.9738\n",
      "Epoch 2/10 - Train Loss: 1.0516 - Val Loss: 0.9746\n",
      "Epoch 3/10 - Train Loss: 1.0510 - Val Loss: 0.9744\n",
      "Epoch 4/10 - Train Loss: 1.0513 - Val Loss: 0.9747\n",
      "Epoch 5/10 - Train Loss: 1.0513 - Val Loss: 0.9746\n",
      "Epoch 6/10 - Train Loss: 1.0513 - Val Loss: 0.9745\n",
      "Epoch 7/10 - Train Loss: 1.0519 - Val Loss: 0.9746\n",
      "Epoch 8/10 - Train Loss: 1.0523 - Val Loss: 0.9743\n",
      "Epoch 9/10 - Train Loss: 1.0516 - Val Loss: 0.9741\n",
      "Epoch 10/10 - Train Loss: 1.0513 - Val Loss: 0.9745\n",
      "X_train shape: torch.Size([20275, 7])\n",
      "y_train shape: torch.Size([20275])\n",
      "Epoch 1/10 - Train Loss: 1.0303 - Val Loss: 1.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 1.0290 - Val Loss: 1.2534\n",
      "Epoch 3/10 - Train Loss: 1.0295 - Val Loss: 1.2561\n",
      "Epoch 4/10 - Train Loss: 1.0295 - Val Loss: 1.2556\n",
      "Epoch 5/10 - Train Loss: 1.0285 - Val Loss: 1.2551\n",
      "Epoch 6/10 - Train Loss: 1.0296 - Val Loss: 1.2563\n",
      "Epoch 7/10 - Train Loss: 1.0295 - Val Loss: 1.2552\n",
      "Epoch 8/10 - Train Loss: 1.0292 - Val Loss: 1.2547\n",
      "Epoch 9/10 - Train Loss: 1.0293 - Val Loss: 1.2557\n",
      "Epoch 10/10 - Train Loss: 1.0291 - Val Loss: 1.2542\n"
     ]
    }
   ],
   "source": [
    "models_r = []\n",
    "\n",
    "for idx in range(len(y_r_train_all[0])):\n",
    "    y_train = y_r_train_all[:,idx]\n",
    "    y_val = y_r_val_all[:,idx]\n",
    "    X_train, y_train = torch.tensor(X_r_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val, y_val = torch.tensor(X_r_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32)\n",
    "    \n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    \n",
    "    model = AgentPredictionRegNN(input_dim=X.shape[1]).to(device)\n",
    "    train_model(model, train_loader, val_loader, nn.MSELoss(), optimizer, epochs=10)\n",
    "    models_r.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPredictionClassNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AgentPredictionClassNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),  # Normalize activations\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, 32),\n",
    "            nn.LeakyReLU(0.01),\n",
    "\n",
    "            nn.Linear(32, num_classes)  # Output logits for each class\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AgentPredictionClassNN(input_dim=X.shape[1], num_classes=len(np.unique(X))).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.6930 - Val Loss: 0.6894\n",
      "Epoch 2/10 - Train Loss: 0.6927 - Val Loss: 0.6892\n",
      "Epoch 3/10 - Train Loss: 0.6936 - Val Loss: 0.6892\n",
      "Epoch 4/10 - Train Loss: 0.6927 - Val Loss: 0.6891\n",
      "Epoch 5/10 - Train Loss: 0.6931 - Val Loss: 0.6894\n",
      "Epoch 6/10 - Train Loss: 0.6952 - Val Loss: 0.6890\n",
      "Epoch 7/10 - Train Loss: 0.6946 - Val Loss: 0.6893\n",
      "Epoch 8/10 - Train Loss: 0.6931 - Val Loss: 0.6897\n",
      "Epoch 9/10 - Train Loss: 0.6937 - Val Loss: 0.6891\n",
      "Epoch 10/10 - Train Loss: 0.6940 - Val Loss: 0.6891\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7238 - Val Loss: 0.7019\n",
      "Epoch 2/10 - Train Loss: 0.7216 - Val Loss: 0.7027\n",
      "Epoch 3/10 - Train Loss: 0.7221 - Val Loss: 0.7018\n",
      "Epoch 4/10 - Train Loss: 0.7230 - Val Loss: 0.7017\n",
      "Epoch 5/10 - Train Loss: 0.7208 - Val Loss: 0.7015\n",
      "Epoch 6/10 - Train Loss: 0.7228 - Val Loss: 0.7014\n",
      "Epoch 7/10 - Train Loss: 0.7216 - Val Loss: 0.7007\n",
      "Epoch 8/10 - Train Loss: 0.7213 - Val Loss: 0.7015\n",
      "Epoch 9/10 - Train Loss: 0.7220 - Val Loss: 0.7022\n",
      "Epoch 10/10 - Train Loss: 0.7219 - Val Loss: 0.7024\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7002 - Val Loss: 0.6958\n",
      "Epoch 2/10 - Train Loss: 0.7006 - Val Loss: 0.6948\n",
      "Epoch 3/10 - Train Loss: 0.7010 - Val Loss: 0.6959\n",
      "Epoch 4/10 - Train Loss: 0.7011 - Val Loss: 0.6963\n",
      "Epoch 5/10 - Train Loss: 0.6993 - Val Loss: 0.6957\n",
      "Epoch 6/10 - Train Loss: 0.7014 - Val Loss: 0.6956\n",
      "Epoch 7/10 - Train Loss: 0.6993 - Val Loss: 0.6959\n",
      "Epoch 8/10 - Train Loss: 0.7004 - Val Loss: 0.6962\n",
      "Epoch 9/10 - Train Loss: 0.7003 - Val Loss: 0.6951\n",
      "Epoch 10/10 - Train Loss: 0.7001 - Val Loss: 0.6951\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7168 - Val Loss: 0.7081\n",
      "Epoch 2/10 - Train Loss: 0.7165 - Val Loss: 0.7075\n",
      "Epoch 3/10 - Train Loss: 0.7143 - Val Loss: 0.7084\n",
      "Epoch 4/10 - Train Loss: 0.7155 - Val Loss: 0.7076\n",
      "Epoch 5/10 - Train Loss: 0.7151 - Val Loss: 0.7077\n",
      "Epoch 6/10 - Train Loss: 0.7161 - Val Loss: 0.7069\n",
      "Epoch 7/10 - Train Loss: 0.7160 - Val Loss: 0.7077\n",
      "Epoch 8/10 - Train Loss: 0.7159 - Val Loss: 0.7079\n",
      "Epoch 9/10 - Train Loss: 0.7157 - Val Loss: 0.7083\n",
      "Epoch 10/10 - Train Loss: 0.7153 - Val Loss: 0.7086\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.6937 - Val Loss: 0.6852\n",
      "Epoch 2/10 - Train Loss: 0.6928 - Val Loss: 0.6853\n",
      "Epoch 3/10 - Train Loss: 0.6942 - Val Loss: 0.6851\n",
      "Epoch 4/10 - Train Loss: 0.6932 - Val Loss: 0.6854\n",
      "Epoch 5/10 - Train Loss: 0.6935 - Val Loss: 0.6850\n",
      "Epoch 6/10 - Train Loss: 0.6928 - Val Loss: 0.6853\n",
      "Epoch 7/10 - Train Loss: 0.6925 - Val Loss: 0.6851\n",
      "Epoch 8/10 - Train Loss: 0.6937 - Val Loss: 0.6852\n",
      "Epoch 9/10 - Train Loss: 0.6936 - Val Loss: 0.6850\n",
      "Epoch 10/10 - Train Loss: 0.6946 - Val Loss: 0.6853\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7167 - Val Loss: 0.7074\n",
      "Epoch 2/10 - Train Loss: 0.7182 - Val Loss: 0.7070\n",
      "Epoch 3/10 - Train Loss: 0.7163 - Val Loss: 0.7068\n",
      "Epoch 4/10 - Train Loss: 0.7166 - Val Loss: 0.7080\n",
      "Epoch 5/10 - Train Loss: 0.7170 - Val Loss: 0.7075\n",
      "Epoch 6/10 - Train Loss: 0.7170 - Val Loss: 0.7060\n",
      "Epoch 7/10 - Train Loss: 0.7158 - Val Loss: 0.7060\n",
      "Epoch 8/10 - Train Loss: 0.7156 - Val Loss: 0.7054\n",
      "Epoch 9/10 - Train Loss: 0.7166 - Val Loss: 0.7068\n",
      "Epoch 10/10 - Train Loss: 0.7153 - Val Loss: 0.7075\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7060 - Val Loss: 0.7051\n",
      "Epoch 2/10 - Train Loss: 0.7047 - Val Loss: 0.7047\n",
      "Epoch 3/10 - Train Loss: 0.7064 - Val Loss: 0.7056\n",
      "Epoch 4/10 - Train Loss: 0.7043 - Val Loss: 0.7054\n",
      "Epoch 5/10 - Train Loss: 0.7048 - Val Loss: 0.7044\n",
      "Epoch 6/10 - Train Loss: 0.7063 - Val Loss: 0.7058\n",
      "Epoch 7/10 - Train Loss: 0.7053 - Val Loss: 0.7045\n",
      "Epoch 8/10 - Train Loss: 0.7059 - Val Loss: 0.7052\n",
      "Epoch 9/10 - Train Loss: 0.7057 - Val Loss: 0.7049\n",
      "Epoch 10/10 - Train Loss: 0.7067 - Val Loss: 0.7049\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7066 - Val Loss: 0.6963\n",
      "Epoch 2/10 - Train Loss: 0.7074 - Val Loss: 0.6967\n",
      "Epoch 3/10 - Train Loss: 0.7078 - Val Loss: 0.6972\n",
      "Epoch 4/10 - Train Loss: 0.7069 - Val Loss: 0.6964\n",
      "Epoch 5/10 - Train Loss: 0.7058 - Val Loss: 0.6965\n",
      "Epoch 6/10 - Train Loss: 0.7074 - Val Loss: 0.6965\n",
      "Epoch 7/10 - Train Loss: 0.7065 - Val Loss: 0.6962\n",
      "Epoch 8/10 - Train Loss: 0.7070 - Val Loss: 0.6966\n",
      "Epoch 9/10 - Train Loss: 0.7072 - Val Loss: 0.6967\n",
      "Epoch 10/10 - Train Loss: 0.7071 - Val Loss: 0.6966\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.6993 - Val Loss: 0.6924\n",
      "Epoch 2/10 - Train Loss: 0.6962 - Val Loss: 0.6924\n",
      "Epoch 3/10 - Train Loss: 0.6976 - Val Loss: 0.6925\n",
      "Epoch 4/10 - Train Loss: 0.6988 - Val Loss: 0.6929\n",
      "Epoch 5/10 - Train Loss: 0.6987 - Val Loss: 0.6925\n",
      "Epoch 6/10 - Train Loss: 0.6993 - Val Loss: 0.6927\n",
      "Epoch 7/10 - Train Loss: 0.6985 - Val Loss: 0.6928\n",
      "Epoch 8/10 - Train Loss: 0.6984 - Val Loss: 0.6925\n",
      "Epoch 9/10 - Train Loss: 0.6971 - Val Loss: 0.6925\n",
      "Epoch 10/10 - Train Loss: 0.6995 - Val Loss: 0.6925\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.4921 - Val Loss: 0.5288\n",
      "Epoch 2/10 - Train Loss: 0.4924 - Val Loss: 0.5256\n",
      "Epoch 3/10 - Train Loss: 0.4921 - Val Loss: 0.5268\n",
      "Epoch 4/10 - Train Loss: 0.4927 - Val Loss: 0.5278\n",
      "Epoch 5/10 - Train Loss: 0.4920 - Val Loss: 0.5248\n",
      "Epoch 6/10 - Train Loss: 0.4935 - Val Loss: 0.5236\n",
      "Epoch 7/10 - Train Loss: 0.4925 - Val Loss: 0.5266\n",
      "Epoch 8/10 - Train Loss: 0.4929 - Val Loss: 0.5256\n",
      "Epoch 9/10 - Train Loss: 0.4926 - Val Loss: 0.5254\n",
      "Epoch 10/10 - Train Loss: 0.4917 - Val Loss: 0.5224\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7406 - Val Loss: 0.7211\n",
      "Epoch 2/10 - Train Loss: 0.7413 - Val Loss: 0.7207\n",
      "Epoch 3/10 - Train Loss: 0.7424 - Val Loss: 0.7217\n",
      "Epoch 4/10 - Train Loss: 0.7406 - Val Loss: 0.7213\n",
      "Epoch 5/10 - Train Loss: 0.7400 - Val Loss: 0.7226\n",
      "Epoch 6/10 - Train Loss: 0.7411 - Val Loss: 0.7219\n",
      "Epoch 7/10 - Train Loss: 0.7426 - Val Loss: 0.7211\n",
      "Epoch 8/10 - Train Loss: 0.7403 - Val Loss: 0.7219\n",
      "Epoch 9/10 - Train Loss: 0.7428 - Val Loss: 0.7212\n",
      "Epoch 10/10 - Train Loss: 0.7403 - Val Loss: 0.7214\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.7042 - Val Loss: 0.7005\n",
      "Epoch 2/10 - Train Loss: 0.7035 - Val Loss: 0.7020\n",
      "Epoch 3/10 - Train Loss: 0.7054 - Val Loss: 0.7017\n",
      "Epoch 4/10 - Train Loss: 0.7051 - Val Loss: 0.7009\n",
      "Epoch 5/10 - Train Loss: 0.7049 - Val Loss: 0.7018\n",
      "Epoch 6/10 - Train Loss: 0.7049 - Val Loss: 0.7021\n",
      "Epoch 7/10 - Train Loss: 0.7040 - Val Loss: 0.7026\n",
      "Epoch 8/10 - Train Loss: 0.7037 - Val Loss: 0.7019\n",
      "Epoch 9/10 - Train Loss: 0.7050 - Val Loss: 0.7020\n",
      "Epoch 10/10 - Train Loss: 0.7038 - Val Loss: 0.7018\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.6041 - Val Loss: 0.6135\n",
      "Epoch 2/10 - Train Loss: 0.6035 - Val Loss: 0.6067\n",
      "Epoch 3/10 - Train Loss: 0.6040 - Val Loss: 0.6046\n",
      "Epoch 4/10 - Train Loss: 0.6036 - Val Loss: 0.6071\n",
      "Epoch 5/10 - Train Loss: 0.6030 - Val Loss: 0.6062\n",
      "Epoch 6/10 - Train Loss: 0.6039 - Val Loss: 0.6100\n",
      "Epoch 7/10 - Train Loss: 0.6049 - Val Loss: 0.6090\n",
      "Epoch 8/10 - Train Loss: 0.6047 - Val Loss: 0.6092\n",
      "Epoch 9/10 - Train Loss: 0.6038 - Val Loss: 0.6054\n",
      "Epoch 10/10 - Train Loss: 0.6054 - Val Loss: 0.6121\n",
      "X_train shape: torch.Size([20253, 7])\n",
      "y_train shape: torch.Size([20253])\n",
      "Epoch 1/10 - Train Loss: 0.6767 - Val Loss: 0.7052\n",
      "Epoch 2/10 - Train Loss: 0.6755 - Val Loss: 0.7072\n",
      "Epoch 3/10 - Train Loss: 0.6775 - Val Loss: 0.7063\n",
      "Epoch 4/10 - Train Loss: 0.6768 - Val Loss: 0.7063\n",
      "Epoch 5/10 - Train Loss: 0.6767 - Val Loss: 0.7072\n",
      "Epoch 6/10 - Train Loss: 0.6760 - Val Loss: 0.7065\n",
      "Epoch 7/10 - Train Loss: 0.6763 - Val Loss: 0.7082\n",
      "Epoch 8/10 - Train Loss: 0.6775 - Val Loss: 0.7068\n",
      "Epoch 9/10 - Train Loss: 0.6771 - Val Loss: 0.7057\n",
      "Epoch 10/10 - Train Loss: 0.6766 - Val Loss: 0.7101\n"
     ]
    }
   ],
   "source": [
    "models_c = []\n",
    "\n",
    "for idx in y_c_train_all.columns:\n",
    "    y_train = y_c_train_all[idx].values  # Convert to numpy array\n",
    "    y_val = y_c_val_all[idx].values  # Convert to numpy array\n",
    "    X_train, y_train = torch.tensor(X_c_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val, y_val = torch.tensor(X_c_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32)\n",
    "    \n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    \n",
    "    model = AgentPredictionClassNN(input_dim=X.shape[1], num_classes=len(np.unique(y_train))).to(device)\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n",
    "    models_c.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 1.0054\n",
      "Final Test Loss: 1.0629\n",
      "Final Test Loss: 1.1000\n",
      "Final Test Loss: 1.0953\n",
      "Final Test Loss: 1.0028\n",
      "Final Test Loss: 1.0386\n",
      "Final Test Loss: 1.0275\n",
      "Final Test Loss: 0.7223\n",
      "Final Test Loss: 0.9706\n",
      "Final Test Loss: 1.0437\n",
      "Final Test Loss: 1.0968\n",
      "Final Test Loss: 0.9995\n",
      "Final Test Loss: 0.8703\n",
      "Final Test Loss: 1.1197\n",
      "Final Test Loss: 1.1003\n",
      "Final Test Loss: 1.0268\n",
      "Final Test Loss: 1.0222\n",
      "Final Test Loss: 0.9894\n",
      "Final Test Loss: 1.0746\n",
      "Final Test Loss: 0.8492\n",
      "Final Test Loss: 0.8945\n",
      "Final Test Loss: 1.0159\n",
      "Final Test Loss: 1.0093\n",
      "Final Test Loss: 1.0510\n",
      "Final Test Loss: 1.0602\n",
      "Final Test Loss: 0.9447\n",
      "Final Test Loss: 1.0762\n",
      "Final Test Loss: 0.9198\n",
      "Final Test Loss: 0.9322\n"
     ]
    }
   ],
   "source": [
    "# For regression NN\n",
    "ys_reg = []\n",
    "\n",
    "for idx in range(len(y_r_train_all[0])):\n",
    "    y_test = y_r_test_all[:, idx]\n",
    "    X_test, y_test = torch.tensor(X_r_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    "    \n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "    \n",
    "    model_reg = models_r[idx]\n",
    "    y_idx = []\n",
    "    \n",
    "    model_reg.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model_reg(X_batch)\n",
    "            y_idx.append(y_pred.cpu().numpy().flatten())\n",
    "            test_loss += nn.MSELoss()(y_pred, y_batch).item()\n",
    "    print(f\"Final Test Loss: {test_loss/len(test_loader):.4f}\")\n",
    "    ys_reg.append(np.concatenate(y_idx))\n",
    "ys_reg = np.array(ys_reg).T\n",
    "y_original_reg = y_scaler.inverse_transform(ys_reg).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.6962\n",
      "Final Test Loss: 0.6960\n",
      "Final Test Loss: 0.6968\n",
      "Final Test Loss: 0.6969\n",
      "Final Test Loss: 0.6955\n",
      "Final Test Loss: 0.6966\n",
      "Final Test Loss: 0.6957\n",
      "Final Test Loss: 0.6959\n",
      "Final Test Loss: 0.6927\n",
      "Final Test Loss: 0.7098\n",
      "Final Test Loss: 0.6952\n",
      "Final Test Loss: 0.6984\n",
      "Final Test Loss: 0.7072\n",
      "Final Test Loss: 0.7107\n"
     ]
    }
   ],
   "source": [
    "# For classification NN\n",
    "ys_class = []\n",
    "\n",
    "for idx in range(len(list(y_c_test_all.columns))):\n",
    "    y_test = y_c_test_all.iloc[:, idx].values\n",
    "    X_test, y_test = torch.tensor(X_c_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)  # Change to long type\n",
    "    \n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
    "    \n",
    "    model_class = models_c[idx]  # Adjust index to get the correct model\n",
    "    y_idx = []\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            y_pred = y_pred.view(-1, y_pred.size(-1))  # Ensure y_pred has shape (N, C)\n",
    "            test_loss += nn.CrossEntropyLoss()(y_pred, y_batch).item()\n",
    "            #y_idx.append(y_pred.cpu().numpy().flatten())\n",
    "            y_idx.extend(y_pred.cpu().numpy().tolist())  # Use extend instead of append\n",
    "    print(f\"Final Test Loss: {test_loss/len(test_loader):.4f}\")\n",
    "    y_idx = np.array(y_idx).argmax(axis=1)  # Get the class with the highest probability\n",
    "    ys_class.append(y_idx)  # Append y_idx to ys_class\n",
    "    #ys_class.append(np.concatenate(y_idx))\n",
    "    \n",
    "ys_class = np.array(ys_class)\n",
    "\n",
    "# Fit the y_encoder with all possible labels\n",
    "all_labels = np.concatenate([y_c_train_all.values.flatten(), y_c_test_all.values.flatten()])\n",
    "y_encoder.fit(all_labels)\n",
    "\n",
    "# Decode the classification predictions\n",
    "y_decoded = [y_encoder.inverse_transform(ys_class[:, i]) for i in range(ys_class.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf(y_true_reg, y_pred_reg, y_true_class, y_pred_class):\n",
    "    y_true_class = np.array(y_true_class)\n",
    "    success = 0\n",
    "    for col_reg in range(y_true_reg.shape[1]):\n",
    "        for row_reg in range(y_true_reg.shape[0]):\n",
    "            if np.abs(y_true_reg[row_reg, col_reg] - y_pred_reg[row_reg, col_reg]) / y_true_reg[row_reg, col_reg] < 0.025:\n",
    "                success += 1\n",
    "    #for col_class in range(y_true_class.shape[1]):\n",
    "        #print(y_true_class[:, col_class])\n",
    "        #print(y_pred_class[:, col_class])\n",
    "        #success += np.sum(y_true_class[:, col_class] == y_pred_class[:, col_class])\n",
    "    success += np.sum(np.sum(y_true_class == y_pred_class.T, axis=1))\n",
    "    \n",
    "    return(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.197857266286505\n"
     ]
    }
   ],
   "source": [
    "# Ensure performance is not redefined as an integer\n",
    "p = perf(y_r_test_all, ys_reg, y_c_test_all, ys_class) / (y_r_test_all.shape[0])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
